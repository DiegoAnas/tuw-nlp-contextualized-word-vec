{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9204259e-3174-43c4-8ea8-e74ddc0e66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c47df05-83db-45a2-a0ef-9cf32029c363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91f5093-2313-4288-84f1-ff1b57155593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 21:11:09.864147: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-29 21:11:09.882020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-29 21:11:09.900536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-29 21:11:09.906019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-29 21:11:09.921596: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-29 21:11:10.946349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from NMT import train_translate, models, BCN, Data_prep_WMT16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c932f2c8-a1ec-44ab-a973-ef674115388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NMT.train_translate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de078e6-60fa-4905-82c0-c98fabfbbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "GLOVE_PATH = \"./data/glove.6B.300d.txt\"\n",
    "EMBS_PATH = \"./data/prep/glove.embs.pickle\"\n",
    "VOCAB_PATH = \"./data/prep/vocab.json\"\n",
    "TRAIN_SRC_PATH = \"./data/prep/train.tok.en\"\n",
    "TRAIN_TGT_PATH = \"./data/prep/train.tok.de\"\n",
    "VAL_SRC_PATH = \"./data/prep/val.tok.en\"\n",
    "VAL_TGT_PATH = \"./data/prep/val.tok.de\"\n",
    "TEST_SRC_PATH = \"./data/prep/test.tok.en\"\n",
    "TEST_TGT_PATH = \"./data/prep/test.tok.de\"\n",
    "MODEL_SAVE_PATH = \"./checkpoints/\"\n",
    "TOKENIZER_EN_PATH = \"./data/prep/tokenizer.en.pickle\"\n",
    "TOKENIZER_DE_PATH = \"./data/prep/tokenizer.de.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31696cd1-6a69-499d-9d8e-5b68a850e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/prep/train.tok.en'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SRC_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6199b10-035f-47a2-8959-84fc27cde42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NMT.Data_prep_WMT16 import preprocess_wmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344592a8-d1c2-4def-b62d-3936b9c56c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gloves saved to ./data/prep/glove.embs.pickle\n",
      " Tokenizer saved to ./data/prep/tokenizer.en.pickle\n",
      " Tokenizer saved to ./data/prep/tokenizer.de.pickle\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the downloaded data\n",
    "train_en, train_de, val_en, val_de, test_en, test_de, embedding_matrix, vocab, i2w, tokenizer_en, tokenizer_de = preprocess_wmt(\"./data/\", \"./data/glove.6B.300d.txt\", \"./data/prep/\")\n",
    "#get loaders from data\n",
    "dataloader = create_dataloader(train_en, train_de, 32)\n",
    "val_dl = create_dataloader(val_en, val_de, 32)\n",
    "en_vocab = tokenizer_en.word_index\n",
    "de_vocab = tokenizer_de.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c3cc83-cd58-4824-8943-5b99773d6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(train_en, train_de, 32)\n",
    "val_dl = create_dataloader(val_en, val_de, 32)\n",
    "en_vocab = tokenizer_en.word_index\n",
    "de_vocab = tokenizer_de.word_index\n",
    "embedding_tensor = torch.from_numpy(embedding_matrix).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a51b1dc-e273-41ab-ae60-d6a064dca876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the preprocessed data\n",
    "import pickle\n",
    "with open(\"./data/prep/tokenizer.en.pickle\", \"rb\") as f:\n",
    "        tokenizer_en = pickle.load(f)\n",
    "with open(\"./data/prep/tokenizer.de.pickle\", \"rb\") as f:\n",
    "        tokenizer_de = pickle.load(f)\n",
    "with open(EMBS_PATH, \"rb\") as f:\n",
    "        combined_embeddings = pickle.load(f)\n",
    "embedding_tensor = torch.from_numpy(combined_embeddings).float().to(device)\n",
    "src_sentences, tgt_sentences = load_tokenized_data(TRAIN_SRC_PATH, TRAIN_TGT_PATH)\n",
    "dataloader = create_dataloader(src_sentences, tgt_sentences, 32)\n",
    "val_src_sentences, val_tgt_sentences = load_tokenized_data(VAL_SRC_PATH, VAL_TGT_PATH)\n",
    "val_dl = create_dataloader(val_src_sentences, val_tgt_sentences, 32)\n",
    "en_vocab = tokenizer_en.word_index\n",
    "de_vocab = tokenizer_de.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e2f83b-2cae-45ff-a71f-2af0564b8434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en vocab 18855 embeddings torch.Size([50000, 300]) de vocab 43315\n"
     ]
    }
   ],
   "source": [
    "print(f\"en vocab {len(en_vocab)} embeddings {embedding_tensor.shape} de vocab {len(de_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed4abfe-f349-42b4-a956-b93c9c746abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model(en_vocab, de_vocab, embedding_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6af95de-c26b-4387-bba0-c99e1ac31c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Loss: 4.7584\n",
      "Validation Loss: 14.8474\n",
      "Checkpoint saved at ./checkpoints/best_checkpoint.pth\n",
      "Best model updated with Validation Loss: 14.8474\n",
      "Epoch [2/100] - Loss: 4.5146\n",
      "Validation Loss: 14.5802\n",
      "Epoch [3/100] - Loss: 4.0544\n",
      "Validation Loss: 13.8854\n",
      "Epoch [4/100] - Loss: 3.7236\n",
      "Validation Loss: 13.2893\n",
      "Epoch [5/100] - Loss: 3.3745\n",
      "Validation Loss: 12.9168\n",
      "Epoch [6/100] - Loss: 3.1454\n",
      "Validation Loss: 12.1383\n",
      "Epoch [7/100] - Loss: 2.9046\n",
      "Validation Loss: 11.8349\n",
      "Epoch [8/100] - Loss: 2.7592\n",
      "Validation Loss: 11.1501\n",
      "Epoch [9/100] - Loss: 2.4608\n",
      "Validation Loss: 10.44\n",
      "Epoch [10/100] - Loss: 2.0866\n",
      "Validation Loss: 10.2392\n",
      "Epoch [11/100] - Loss: 1.9794\n",
      "Validation Loss: 9.9003\n",
      "Epoch [12/100] - Loss: 1.7968\n",
      "Validation Loss: 9.5641\n",
      "Epoch [13/100] - Loss: 1.426\n",
      "Validation Loss: 8.8381\n",
      "Epoch [14/100] - Loss: 1.0541\n",
      "Validation Loss: 8.3593\n",
      "Epoch [15/100] - Loss: 0.7617\n",
      "Validation Loss: 7.8915\n",
      "Epoch [16/100] - Loss: 0.5675\n",
      "Validation Loss: 7.5884\n",
      "Epoch [17/100] - Loss: 0.2926\n",
      "Validation Loss: 7.3819\n",
      "Epoch [18/100] - Loss: 0.184\n",
      "Validation Loss: 6.9687\n",
      "Epoch [19/100] - Loss: 0.1\n",
      "Validation Loss: 6.2223\n",
      "Epoch [20/100] - Loss: 0.1\n",
      "Validation Loss: 5.6433\n",
      "Checkpoint saved at ./checkpoints/final_checkpoint.pth\n",
      "Model saved to ./checkpoints/final_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "train_model(model, dataloader, validation_dl= val_dl, vocab_size=len(de_vocab), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e4ce21-52e1-4372-b20d-8669c1b2669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMTModel(\n",
       "  (encoder): Encoder(\n",
       "    (dropout_l): Dropout(p=0.2, inplace=False)\n",
       "    (dropout_l2): Dropout(p=0.2, inplace=False)\n",
       "    (embedding): Embedding(50000, 300, padding_idx=0)\n",
       "    (LSTM): LSTM(300, 150, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(43315, 300, padding_idx=0)\n",
       "    (dropout_l1): Dropout(p=0.2, inplace=False)\n",
       "    (LSTM): LSTM(600, 300, num_layers=2, batch_first=True, dropout=0.2)\n",
       "    (dropout_l2): Dropout(p=0.2, inplace=False)\n",
       "    (linear_attn_in): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (linear_attn_out): Linear(in_features=600, out_features=300, bias=True)\n",
       "    (dropout_l3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear): Linear(in_features=300, out_features=43315, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6267abe-43e3-413a-a66c-58e1a12b2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src_sentences, test_tgt_sentences = load_tokenized_data(TEST_SRC_PATH, TEST_TGT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7064e40-50db-4c86-a440-429dbebe25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = create_dataloader(test_src_sentences, test_tgt_sentences, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27dc7718-04cc-4f6a-8562-03cab9861bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   3, 4329,  169,  ...,    0,    0,    0],\n",
       "        [   3,  184, 4067,  ...,    0,    0,    0],\n",
       "        [   3,    2, 1700,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   3,   33,    2,  ...,    0,    0,    0],\n",
       "        [   3, 6934,  150,  ...,    0,    0,    0],\n",
       "        [   3,   13,  178,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_dl))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0b9c06d-c4af-4ff5-a706-a7c28aca01c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.legacy.preprocessing.text.Tokenizer at 0x7f4238b20c10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79e1b5d-e80d-44bc-962c-f3fad64f0582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1 7656 29494 2592 618 12544 9503 15708 330 680 13206 1 5091 12741 2475 1 857 2170 104 3853 12335 10058 2553 2994 1832 162 7222 1 104 1 1 4581 1 5327 21582 23897 104 21603 45593 13206\n",
      "0\t1422 23440 37202 1076 283 4304 1685 12208 18119 21204 3612 1 48826 35598 1 1 1 23082 1596 12142 1 7723 6539 1 5600 20962 1 12820 2575 10939 6850 1502 2456 6995 5435 40686 30243 7039 1 23082\n",
      "0\t26041 8461 26041 8461 26041 8461 257 9820 197 1979 7836 2647 1 618 1 1221 6610 1685 389 23940 6850 1 37339 31010 2182 1 1 26584 585 10939 8344 1 127 565 1 13831 13831 6573 2398 1136\n",
      "0\t1 32093 14138 1 1 1 494 13844 6950 19757 20934 1 4117 4869 1 1401 8574 6849 1 21965 21965 3784 40491 4869 1 43 16031 2747 585 1 1 8020 1531 17912 2134 2981 31059 1 1 19496\n",
      "0\t10472 13841 23447 2981 198 62 19795 1010 2160 330 661 10744 2189 7146 4137 7176 4869 11761 1 1 8020 7841 240 1 1305 1 27945 19028 1396 1832 1880 31103 1252 7592 1 62 8020 24481 1 100\n",
      "0\t3726 2747 33244 6640 1 1 1834 1 1 40491 11900 24007 1 40491 10520 1 293 25495 27151 1 296 5874 4833 31132 1 5381 10259 405 1594 32098 68 14259 686 9340 209 1 574 1 127 0\n",
      "0\t7868 10472 13841 127 23082 5322 16328 1 24438 1 1 2981 238 1 10420 1 173 49393 1 2573 9820 1401 7078 1 1 3840 330 1 104 2310 1 870 1401 1248 12841 268 197 3338 49393 9820\n",
      "0\t1880 7222 10472 13841 1 1802 1744 5607 8045 1 1908 6850 1 8628 2511 25403 3803 10472 13841 2157 1 1 1908 17744 10635 1706 5061 246 190 23024 33041 10472 13841 2157 1 1 1908 1 20981 1\n",
      "0\t10472 13841 1979 23447 504 6850 7075 1 28700 7145 1 284 878 1 16185 292 1196 3973 2504 292 1656 1800 33351 1 23447 32137 326 417 330 360 1 1 1 1105 2189 636 8346 13726 2106 9820\n",
      "0\t1979 6160 982 10472 13841 40531 37339 1 3721 37384 3225 1 1820 2691 20982 1979 127 23934 4550 7176 4609 30284 9882 1820 43275 40491 4869 292 159 1610 43275 296 49406 1 3179 8468 7075 1 4869 5478\n",
      "1\t1298 1 1 1 2830 293 574 1 9820 32098 2778 268 4404 12938 9808 585 1204 39078 1 1 1 104 1 7251 771 62 11598 1681 16483 1645 257 3480 1076 4932 10636 179 663 3348 1 1\n",
      "1\t2288 1 305 7222 12845 6850 7952 222 574 6850 127 1 2981 487 10818 37169 222 308 10014 1 3621 1 2334 22636 1 3396 7366 9952 173 12142 19740 4525 6850 33016 1507 17566 34585 1094 6388 12561\n",
      "1\t191 1 1 6850 4016 6850 9299 1 3612 1 7104 1122 1 62 1309 1 42771 1 5138 6388 6850 1 607 19530 6850 1 10951 1 1555 34585 2552 719 37032 7588 1 617 1 104 426 1\n",
      "1\t362 6850 585 1204 2079 23954 484 1 747 501 29314 29289 8883 19231 362 217 10014 5120 217 653 22286 21894 27305 870 616 1216 1634 3451 8080 1 45536 533 489 1 1636 3038 7078 2334 3088 6850\n",
      "1\t1 1 6850 5249 4255 22230 4959 1 1 9209 17566 971 3026 9720 228 2334 16682 2334 747 610 24827 1 1031 4604 1 7895 9952 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "1\t1664 292 470 1 2357 197 1 2357 27992 3397 2644 1594 502 3681 257 1 14125 662 10256 5105 385 1 494 209 2742 6263 5138 6388 1 198 1896 1 3833 1 45955 1 9297 7916 5299 533\n",
      "1\t885 6850 3973 21562 29316 16855 6850 25409 7197 8080 29316 877 533 23581 2025 154 1 295 747 533 11819 43377 1741 1 254 1945 719 1 292 9404 9268 7612 1 1076 37188 1281 20583 62 1 1674\n",
      "1\t750 1881 1 134 1176 253 533 14852 653 1 870 2753 1 3020 12400 2235 3300 1 259 1176 228 11809 2269 747 2037 1 1 3278 1 6388 191 34579 6592 1 3078 8768 2189 9557 24879 6388\n",
      "1\t603 19027 720 6850 1 1 6388 1707 37202 209 1164 23911 40627 1550 6388 1058 469 7952 1377 1531 262 903 6388 293 550 6850 9340 148 1 14363 4959 22999 40748 1733 31107 9720 2115 356 11620 1821\n",
      "1\t127 854 1 1 293 42730 10194 5359 1 1221 31036 340 1451 1196 16506 1196 1 1 1204 1 1474 1 3844 330 1 2809 25 8993 1 12208 1 5487 22999 1 340 1 771 5018 1 1221\n",
      "1\t1 6850 158 1888 3711 495 654 2334 3319 10014 722 34585 292 1 22652 971 4593 2640 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "1\t23976 7146 219 10014 13961 762 326 146 735 2107 14377 15717 360 238 24439 16162 17029 610 68 3718 24439 433 656 14377 405 6305 4493 1740 8676 533 25503 253 5710 1200 725 171 971 5937 347 725\n",
      "1\t2244 1 971 1 33364 14377 127 2343 1674 747 8050 15563 127 24439 9209 31183 13222 402 2936 1 5488 1 1719 1 148 16013 9036 14377 24439 5963 1 1 11826 1 2343 1 6737 301 12831 329\n",
      "1\t18105 1 1 1 40627 37202 4593 5479 1 29472 1 809 254 7222 814 2632 1 296 653 987 8045 2778 12741 1105 1342 34585 5425 40633 820 2326 4982 2491 238 998 1922 7146 2616 253 21508 62\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en.sequences_to_texts(next(iter(dataloader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cc103-4bff-4474-a235-d190f7009fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
