{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VdFfVbmMife"
      },
      "source": [
        "# 192.039 Deep Learning for Natural Language Processing W2024\n",
        "## Seq2Seq Translation German to English\n",
        "Diego Anas Rejas Haddioui"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwYKBLzSPFgt",
        "outputId": "c49b962d-beee-49fc-c179-9d971f5e57af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YavPCfIaOyGv",
        "outputId": "bbe8babb-cbb9-46c3-c0da-2c8bf1c663a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mij4j2zhMifu"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAnDZlttMifv"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdyIkQBCMifx"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOP7DTY3Mify"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def readLangs(input_file, reverse=False)-> Tuple[Lang,Lang,Tuple[str,str]]:\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    with open(input_file, encoding='utf-8') as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "\n",
        "    # Only keep the first two parts (English and German sentences)\n",
        "    pairs = []\n",
        "    for line in lines:\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) >= 2:  # Ensure there are at least two parts\n",
        "            english, german = parts[0], parts[1]\n",
        "            pairs.append([normalizeString(english), normalizeString(german)])\n",
        "\n",
        "    # Reverse pairs if necessary\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(\"eng\")  # German-to-English, so input is English when reversed\n",
        "        output_lang = Lang(\"deu\")\n",
        "    else:\n",
        "        input_lang = Lang(\"deu\")\n",
        "        output_lang = Lang(\"eng\")\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7PV_DtEMif0"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jgQAIQOMif1",
        "outputId": "008f1fad-20c3-47d9-81dc-100d89dbee52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 152820 sentence pairs\n",
            "Trimmed to 9126 sentence pairs\n",
            "Counting words...\n",
            "Counted words: eng 4649 deu 3032\n",
            "['er erblindet', 'he s going blind']\n"
          ]
        }
      ],
      "source": [
        "# [Prepare Data with Train-Test Split]\n",
        "def prepareData(test_ratio=0.2, reverse=False):\n",
        "    input_file = \"/content/drive/MyDrive/Datasets/deu.txt\"\n",
        "    input_lang, output_lang, pairs = readLangs(input_file, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\", input_lang.name, input_lang.n_words, output_lang.name, output_lang.n_words)\n",
        "\n",
        "    # Split into training and test pairs\n",
        "    random.shuffle(pairs)\n",
        "    test_size = int(len(pairs) * test_ratio)\n",
        "    test_pairs = pairs[:test_size]\n",
        "    train_pairs = pairs[test_size:]\n",
        "    return input_lang, output_lang, train_pairs, test_pairs\n",
        "\n",
        "# Run the updated prepareData function\n",
        "#input_lang, output_lang, pairs = prepareData(reverse=True)\n",
        "#print(random.choice(pairs))\n",
        "input_lang, output_lang, train_pairs, test_pairs = prepareData(reverse=True)\n",
        "print(random.choice(test_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "sv1sytvLM5mp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX7FpSn7Mif4"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjlBWN0TMif5"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjK4kRstMif5"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMjug5VXMif6"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader_old(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData(reverse=True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader\n",
        "\n",
        "\n",
        "#  [Load Dataloader for Train and Test Sets]\n",
        "def get_dataloader(pairs, batch_size):\n",
        "    input_ids = np.zeros((len(pairs), MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((len(pairs), MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    dataset = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                            torch.LongTensor(target_ids).to(device))\n",
        "    sampler = RandomSampler(dataset)\n",
        "    dataloader = DataLoader(dataset, sampler=sampler, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6DDV4qtMif7"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxJ33RR5Mif8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_K_WSbHMif9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-PmyHw5Mif8"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Training & Evaluation"
      ],
      "metadata": {
        "id": "4muvkCKtNEZY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A3GsNepMif9"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                #decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okPExlp-Mif-"
      },
      "outputs": [],
      "source": [
        "def run_evaluation(encoder:nn.Module, decoder:nn.Module, pairs:Tuple[str,str], input_lang:Lang, output_lang:Lang, tokenizers=None, print_sentences=False):\n",
        "    import evaluate as hfeval\n",
        "    from nltk.translate import gleu_score\n",
        "    print(\"Evaluating model on test set:\")\n",
        "    predictions = []\n",
        "    predictions_tokenized = []\n",
        "    references = []\n",
        "    references_tokenized = []\n",
        "    for pair in pairs:\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        references.append(pair[1])\n",
        "        references_tokenized.append(pair[1].split(\" \"))\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        predictions.append(output_sentence)\n",
        "        predictions_tokenized.append(output_words)\n",
        "        if print_sentences:\n",
        "          print('>', pair[0])\n",
        "          print('=', pair[1])\n",
        "          print(f\"<{output_sentence}\\n\")\n",
        "\n",
        "    bleu = hfeval.load(\"bleu\")\n",
        "    #bleu = hfeval.load(\"bleu\", smoothing=True) # same as sacrebleu with default params\n",
        "    sacrebleu = hfeval.load(\"sacrebleu\") # default smooth_method=\"exp\"\n",
        "\n",
        "    bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "    sacrebleu_score = sacrebleu.compute(predictions=predictions, references=references)\n",
        "    gleu_number = gleu_score.corpus_gleu(list_of_references = references_tokenized, hypotheses= predictions_tokenized, min_len=1, max_len=4)\n",
        "\n",
        "    print(\"Metric scores:\")\n",
        "    print(f\"Corpus BLEU Score on test set: {bleu_score}\")\n",
        "    print(f\"Corpus SacreBLEU Score on test set: {sacrebleu_score}\")\n",
        "    print(f\"Corpus GLEU Score on test set: {gleu_number}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "YBc88RtikSXn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPtjqi4BMigA",
        "outputId": "26b26509-3edc-4ddf-8d4b-f3131e880b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained for 2 epochs with hidden size 128 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.07280072530446821, 'precisions': [0.3240149509422208, 0.15793773259508034, 0.04493037423846823, 0.01221664178091489], 'brevity_penalty': 1.0, 'length_ratio': 1.2335030256459514, 'translation_length': 12842, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 7.280072530446821, 'counts': [4161, 1740, 413, 90], 'totals': [12842, 11017, 9192, 7367], 'precisions': [32.401495094222085, 15.793773259508033, 4.493037423846824, 1.221664178091489], 'bp': 1.0, 'sys_len': 12842, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03637901861252115\n",
            "0m 55s (- 0m 33s) (5 62%) 1.7534\n",
            "Model trained for 8 epochs with hidden size 128 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.23346853524420674, 'precisions': [0.4951853429910524, 0.30080726538849645, 0.17971552257266543, 0.11098690514212711], 'brevity_penalty': 1.0, 'length_ratio': 1.1271731822111228, 'translation_length': 11735, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 23.346853524420673, 'counts': [5811, 2981, 1453, 695], 'totals': [11735, 9910, 8085, 6262], 'precisions': [49.51853429910524, 30.080726538849646, 17.97155225726654, 11.098690514212711], 'bp': 1.0, 'sys_len': 11735, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.033112946146882115\n",
            "0m 54s (- 1m 16s) (5 41%) 1.7534\n",
            "1m 49s (- 0m 21s) (10 83%) 0.7641\n",
            "Model trained for 12 epochs with hidden size 128 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.28760957273694315, 'precisions': [0.5387512041334618, 0.34948926412341047, 0.23053159994851333, 0.1576379542395693], 'brevity_penalty': 1.0, 'length_ratio': 1.0968206704447219, 'translation_length': 11419, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 28.760957273694302, 'counts': [6152, 3353, 1791, 937], 'totals': [11419, 9594, 7769, 5944], 'precisions': [53.875120413346174, 34.948926412341045, 23.05315999485133, 15.763795423956932], 'bp': 1.0, 'sys_len': 11419, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.0323242688558235\n",
            "Model trained for 2 epochs with hidden size 128 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.05456605250387642, 'precisions': [0.28958485069191553, 0.1351532969340613, 0.03015873015873016, 0.007510599636583889], 'brevity_penalty': 1.0, 'length_ratio': 1.318797425799635, 'translation_length': 13730, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 5.4566052503876445, 'counts': [3976, 1609, 304, 62], 'totals': [13730, 11905, 10080, 8255], 'precisions': [28.95848506919155, 13.515329693406132, 3.015873015873016, 0.7510599636583889], 'bp': 1.0, 'sys_len': 13730, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03943555218690089\n",
            "0m 27s (- 0m 16s) (5 62%) 2.0476\n",
            "Model trained for 8 epochs with hidden size 128 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.17648042617153592, 'precisions': [0.42845736186521877, 0.24843443312459107, 0.1308316430020284, 0.06965527025109945], 'brevity_penalty': 1.0, 'length_ratio': 1.2029584093746999, 'translation_length': 12524, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 17.648042617153592, 'counts': [5366, 2658, 1161, 491], 'totals': [12524, 10699, 8874, 7049], 'precisions': [42.845736186521876, 24.843443312459108, 13.08316430020284, 6.965527025109945], 'bp': 1.0, 'sys_len': 12524, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.030889683298927547\n",
            "0m 31s (- 0m 43s) (5 41%) 2.0182\n",
            "0m 59s (- 0m 11s) (10 83%) 1.0445\n",
            "Model trained for 12 epochs with hidden size 128 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.24178994702676526, 'precisions': [0.50105565408327, 0.30950479233226835, 0.18959833964106948, 0.11624253848570532], 'brevity_penalty': 1.0, 'length_ratio': 1.1373547209682067, 'translation_length': 11841, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 24.178994702676516, 'counts': [5933, 3100, 1553, 740], 'totals': [11841, 10016, 8191, 6366], 'precisions': [50.105565408327, 30.950479233226837, 18.959833964106945, 11.62425384857053], 'bp': 1.0, 'sys_len': 11841, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.032114329185458895\n",
            "Model trained for 2 epochs with hidden size 192 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.12376276302062457, 'precisions': [0.393029446015638, 0.20721780915955673, 0.08612040133779264, 0.033450435313884225], 'brevity_penalty': 1.0, 'length_ratio': 1.1547401786571896, 'translation_length': 12022, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 12.376276302062452, 'counts': [4725, 2113, 721, 219], 'totals': [12022, 10197, 8372, 6547], 'precisions': [39.3029446015638, 20.721780915955673, 8.612040133779264, 3.345043531388422], 'bp': 1.0, 'sys_len': 12022, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03472920747525014\n",
            "0m 57s (- 0m 34s) (5 62%) 1.4571\n",
            "Model trained for 8 epochs with hidden size 192 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.31586921544491725, 'precisions': [0.5648814281907807, 0.3757684969260123, 0.25522407675121567, 0.18375108038029386], 'brevity_penalty': 1.0, 'length_ratio': 1.0814523100566709, 'translation_length': 11259, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 31.586921544491723, 'counts': [6360, 3545, 1942, 1063], 'totals': [11259, 9434, 7609, 5785], 'precisions': [56.48814281907807, 37.57684969260123, 25.522407675121567, 18.375108038029385], 'bp': 1.0, 'sys_len': 11259, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.033961170675166616\n",
            "0m 56s (- 1m 18s) (5 41%) 1.4803\n",
            "1m 52s (- 0m 22s) (10 83%) 0.4199\n",
            "Model trained for 12 epochs with hidden size 192 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.32768351512535776, 'precisions': [0.5713414102675848, 0.38619402985074625, 0.26856704589032343, 0.19456485495165055], 'brevity_penalty': 1.0, 'length_ratio': 1.1020074920756893, 'translation_length': 11473, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 32.76835151253578, 'counts': [6555, 3726, 2101, 1167], 'totals': [11473, 9648, 7823, 5998], 'precisions': [57.13414102675848, 38.61940298507463, 26.85670458903234, 19.456485495165055], 'bp': 1.0, 'sys_len': 11473, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03460168485328207\n",
            "Model trained for 2 epochs with hidden size 192 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.08894548841594821, 'precisions': [0.33513175385096566, 0.17283838015322875, 0.0589780063464274, 0.018321028165162703], 'brevity_penalty': 1.0, 'length_ratio': 1.2284122562674096, 'translation_length': 12789, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 8.894548841594816, 'counts': [4286, 1895, 539, 134], 'totals': [12789, 10964, 9139, 7314], 'precisions': [33.51317538509657, 17.283838015322875, 5.89780063464274, 1.8321028165162703], 'bp': 1.0, 'sys_len': 12789, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03340974491537824\n",
            "0m 28s (- 0m 17s) (5 62%) 1.7359\n",
            "Model trained for 8 epochs with hidden size 192 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.27253758037624914, 'precisions': [0.5286584827342578, 0.3362813223836597, 0.21451844128763195, 0.14466484268125854], 'brevity_penalty': 1.0, 'length_ratio': 1.0875996542118913, 'translation_length': 11323, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 27.25375803762492, 'counts': [5986, 3194, 1646, 846], 'totals': [11323, 9498, 7673, 5848], 'precisions': [52.86584827342577, 33.62813223836597, 21.451844128763195, 14.466484268125855], 'bp': 1.0, 'sys_len': 11323, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.034458954150606916\n",
            "0m 28s (- 0m 40s) (5 41%) 1.7474\n",
            "0m 57s (- 0m 11s) (10 83%) 0.6753\n",
            "Model trained for 12 epochs with hidden size 192 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.32697982291253136, 'precisions': [0.5760215536596318, 0.3886143931256713, 0.2670674682698731, 0.19120762711864406], 'brevity_penalty': 1.0, 'length_ratio': 1.0695418307559312, 'translation_length': 11135, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 32.69798229125315, 'counts': [6414, 3618, 1999, 1083], 'totals': [11135, 9310, 7485, 5664], 'precisions': [57.60215536596318, 38.861439312567136, 26.70674682698731, 19.12076271186441], 'bp': 1.0, 'sys_len': 11135, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03513410299344907\n",
            "Model trained for 2 epochs with hidden size 256 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.13964434393144723, 'precisions': [0.40237307288723867, 0.2169632714880727, 0.0971507037418469, 0.04483656349435927], 'brevity_penalty': 1.0, 'length_ratio': 1.1899913552972816, 'translation_length': 12389, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 13.964434393144725, 'counts': [4985, 2292, 849, 310], 'totals': [12389, 10564, 8739, 6914], 'precisions': [40.23730728872387, 21.69632714880727, 9.71507037418469, 4.483656349435927], 'bp': 1.0, 'sys_len': 12389, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03240149230847856\n",
            "0m 57s (- 0m 34s) (5 62%) 1.2608\n",
            "Model trained for 8 epochs with hidden size 256 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.3296345224962513, 'precisions': [0.5750932007811113, 0.3807859336934647, 0.2700892857142857, 0.19962010015541357], 'brevity_penalty': 1.0, 'length_ratio': 1.082124675823648, 'translation_length': 11266, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 32.96345224962512, 'counts': [6479, 3595, 2057, 1156], 'totals': [11266, 9441, 7616, 5791], 'precisions': [57.50932007811113, 38.078593369346464, 27.008928571428573, 19.962010015541356], 'bp': 1.0, 'sys_len': 11266, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03448775120171425\n",
            "0m 58s (- 1m 21s) (5 41%) 1.2721\n",
            "1m 56s (- 0m 23s) (10 83%) 0.2308\n",
            "Model trained for 12 epochs with hidden size 256 and batch size 16\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.37540201309597304, 'precisions': [0.619774011299435, 0.4250142126208073, 0.31076040172166425, 0.2426184926184926], 'brevity_penalty': 1.0, 'length_ratio': 1.0200749207568918, 'translation_length': 10620, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 37.54020130959731, 'counts': [6582, 3738, 2166, 1249], 'totals': [10620, 8795, 6970, 5148], 'precisions': [61.9774011299435, 42.501421262080726, 31.076040172166426, 24.26184926184926], 'bp': 1.0, 'sys_len': 10620, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03670814833343756\n",
            "Model trained for 2 epochs with hidden size 256 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.0984741050192848, 'precisions': [0.3451072538467369, 0.17478888106966925, 0.06434035418631458, 0.024229074889867842], 'brevity_penalty': 1.0, 'length_ratio': 1.2672173662472386, 'translation_length': 13193, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 9.847410501928476, 'counts': [4553, 1987, 614, 187], 'totals': [13193, 11368, 9543, 7718], 'precisions': [34.51072538467369, 17.478888106966924, 6.434035418631457, 2.4229074889867843], 'bp': 1.0, 'sys_len': 13193, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03128982018972108\n",
            "0m 28s (- 0m 17s) (5 62%) 1.5540\n",
            "Model trained for 8 epochs with hidden size 256 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.3279341355429433, 'precisions': [0.5751119068934646, 0.3895131086142322, 0.26875, 0.19209833187006145], 'brevity_penalty': 1.0, 'length_ratio': 1.0729036595908175, 'translation_length': 11170, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 32.79341355429434, 'counts': [6424, 3640, 2021, 1094], 'totals': [11170, 9345, 7520, 5695], 'precisions': [57.51119068934646, 38.951310861423224, 26.875, 19.209833187006147], 'bp': 1.0, 'sys_len': 11170, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.0342939143677151\n",
            "0m 29s (- 0m 41s) (5 41%) 1.5289\n",
            "0m 59s (- 0m 11s) (10 83%) 0.4064\n",
            "Model trained for 12 epochs with hidden size 256 and batch size 32\n",
            "Evaluating model on test set:\n",
            "Metric scores:\n",
            "Corpus BLEU Score on test set: {'bleu': 0.3703635695558324, 'precisions': [0.6093577981651376, 0.42446280991735535, 0.30896551724137933, 0.235445836403832], 'brevity_penalty': 1.0, 'length_ratio': 1.0469695514359811, 'translation_length': 10900, 'reference_length': 10411}\n",
            "Corpus SacreBLEU Score on test set: {'score': 37.03635695558324, 'counts': [6642, 3852, 2240, 1278], 'totals': [10900, 9075, 7250, 5428], 'precisions': [60.93577981651376, 42.446280991735534, 30.896551724137932, 23.5445836403832], 'bp': 1.0, 'sys_len': 10900, 'ref_len': 10411}\n",
            "Corpus GLEU Score on test set: 0.03538405753308757\n"
          ]
        }
      ],
      "source": [
        "hidden_sizes = [128,192,256]\n",
        "batch_sizes = [16,32]\n",
        "num_epochs = [2,8,12]\n",
        "for hidden_size in hidden_sizes:\n",
        "    for batch_size in batch_sizes:\n",
        "        for num_epoch in num_epochs:\n",
        "            #input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "            train_dataloader = get_dataloader(train_pairs, batch_size)\n",
        "            test_dataloader = get_dataloader(test_pairs, batch_size)\n",
        "\n",
        "            encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "            decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "            train(train_dataloader, encoder, decoder, num_epoch, print_every=5, plot_every=5)\n",
        "            print(f\"Model trained for {num_epoch} epochs with hidden size {hidden_size} and batch size {batch_size}\")\n",
        "            encoder.eval()\n",
        "            decoder.eval()\n",
        "            run_evaluation(encoder, decoder, test_pairs, input_lang, output_lang)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first we observed how the metrics Bleu, with ```smooth=True```  and SacreBleu, with ```exp``` smooth method, reported the same number. So decided not to use smoothing in the calculation of BLEU, and the metrics still coincided.\n",
        "\n",
        "The following tables show the configurations that achieved the top 5 metrics.\n",
        "\n",
        "| Batch size | Epochs | Hidden size | BLEU / SacreBLEU |\n",
        "|------------|--------|-------------|------------------|\n",
        "| 16         | 12     | 256         | 37.5402013095973 |\n",
        "| 32         | 12     | 256         | 37.0363569555832 |\n",
        "| 16         | 8      | 256         | 32.9634522496251 |\n",
        "| 32         | 8      | 256         | 32.7934135542943 |\n",
        "| 16         | 12     | 192         | 32.7683515125358 |\n",
        "\n",
        "| Batch size | Epochs | Hidden size | GLEU               |\n",
        "|------------|--------|-------------|--------------------|\n",
        "| 32         | 2      | 128         | 0.0394355521869009 |\n",
        "| 16         | 12     | 256         | 0.0367081483334376 |\n",
        "| 16         | 2      | 128         | 0.0363790186125212 |\n",
        "| 32         | 12     | 256         | 0.0353840575330876 |\n",
        "| 32         | 12     | 192         | 0.0351341029934491 |\n",
        "\n",
        "For the BLEU metric, we can see the size of the GRU layer is the one that affects the scores the most, followed by the number of epochs.\n",
        "\n",
        "Using GLEU metric, #1 and #3 configuration somehow obtained while using the lowest number of epochs and smallest hidden size.\n",
        "\n"
      ],
      "metadata": {
        "id": "5KmREdXLjioW"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}