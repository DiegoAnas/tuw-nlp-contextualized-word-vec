{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzvEreYCU24z",
        "outputId": "a77ab11c-eba2-4a46-ec46-3580f26d3b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tuw-nlp-contextualized-word-vec' already exists and is not an empty directory.\n",
            "/content/tuw-nlp-contextualized-word-vec\n",
            "Already on 'devD2'\n",
            "Your branch is up to date with 'origin/devD2'.\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 12 (delta 6), reused 12 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.32 KiB | 225.00 KiB/s, done.\n",
            "From https://github.com/DiegoAnas/tuw-nlp-contextualized-word-vec\n",
            "   fd67d06..0281ba8  devD2      -> origin/devD2\n",
            "Updating fd67d06..0281ba8\n",
            "Fast-forward\n",
            " NMT/BCN.py | 23 \u001b[32m+++++++++++\u001b[m\u001b[31m------------\u001b[m\n",
            " 1 file changed, 11 insertions(+), 12 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/DiegoAnas/tuw-nlp-contextualized-word-vec.git\n",
        "%cd tuw-nlp-contextualized-word-vec\n",
        "!git checkout devD2\n",
        "!git pull\n",
        "#copy the library to the same directory as this notebook\n",
        "!cp -r NMT .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tJ6_hSdU245"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "sentence_len = 30\n",
        "rnn_size = 300\n",
        "cove = rnn_size\n",
        "glove = 300\n",
        "word_vec_dim = glove\n",
        "glove_cove = glove+cove\n",
        "bcn_fc_size = 128\n",
        "maxout_c = 4 #TODO what does this do\n",
        "dropout = 0.15\n",
        "target_labels = 2\n",
        "vocab_size = 50000\n",
        "params = {\"word_vec_size\": word_vec_dim,\n",
        "          \"nmt_hidden_size\": rnn_size,\n",
        "          \"fc_hidden_size\": bcn_fc_size,\n",
        "          \"bilstm_encoder_size\": 256,\n",
        "          \"bilstm_integrator_size\": 256,\n",
        "          \"maxout_channels\": maxout_c,\n",
        "          \"device\":\"cpu\",\n",
        "          \"dropout\": dropout}"
      ],
      "metadata": {
        "id": "bRjQ8kFkwldk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -l ./glove.6B.zip\n",
        "!unzip -j ./glove.6B.zip glove.6B.300d.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWcqR-_Z86_2",
        "outputId": "d3184e5f-f90d-4888-accb-6712d69d9fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-29 14:03:49--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-01-29 14:03:49--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.13MB/s    in 2m 39s  \n",
            "\n",
            "2025-01-29 14:06:29 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  ./glove.6B.zip\n",
            "  Length      Date    Time    Name\n",
            "---------  ---------- -----   ----\n",
            "171350079  2014-08-04 20:15   glove.6B.50d.txt\n",
            "347116733  2014-08-04 20:14   glove.6B.100d.txt\n",
            "693432828  2014-08-04 20:14   glove.6B.200d.txt\n",
            "1037962819  2014-08-27 19:19   glove.6B.300d.txt\n",
            "---------                     -------\n",
            "2249862459                     4 files\n",
            "Archive:  ./glove.6B.zip\n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0_qfF7B2Ttd",
        "outputId": "bcd543ea-4f6b-4297-e39c-bef3c90d0532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1855628\n",
            "-rw-rw-r-- 1 root root 1037962819 Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-r--r-- 1 root root  862182613 Oct 25  2015 glove.6B.zip\n",
            "drwxr-xr-x 3 root root       4096 Jan 29 14:22 NMT\n",
            "-rw-r--r-- 1 root root        904 Jan 29 14:03 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qClPCMbrCYIq",
        "outputId": "fb04ad9c-a499-44eb-dd7c-459d93e0bb7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NMT.load_WMT16 import load_tokenizer\n",
        "tokenizer_path = \"./NMT/wmt16_tokenizer.pkl\"\n",
        "tokenizer = load_tokenizer(tokenizer_path)\n",
        "vocab = tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvmCsaxe2NF6",
        "outputId": "9b20fe1d-925f-4d12-ecd4-38bd8b13d9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded from ./NMT/wmt16_tokenizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NMT.Data_prep_WMT16 import create_embedding_indexmatrix\n",
        "glove_embs = create_embedding_indexmatrix(\"./glove.6B.300d.txt\", vocab, vocab_size)"
      ],
      "metadata": {
        "id": "vRRW3BAfCcst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppqK6ymyL--Z",
        "outputId": "2af9d18b-b17c-4be1-df58-64dcccb92432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('<unk>', 1), ('2', 2), ('3', 3)])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NMT import models\n",
        "encoder = models.Encoder(num_layers=2, bidirectional=True,\n",
        "                         dropout=dropout, rnn_size=rnn_size,\n",
        "                         word_vec_dim=word_vec_dim, dict_size=vocab_size,\n",
        "                         vocab=vocab, glove_embeddings= glove_embs)\n",
        "decoder = models.Decoder(num_layers=2, bidirectional=False, dropout=dropout, rnn_size=rnn_size, word_vec_dim=word_vec_dim, dict_size=vocab_size)\n",
        "model = models.NMTModel(encoder=encoder, decoder=decoder, rnn_size=rnn_size, tgt_dict_size=vocab_size)"
      ],
      "metadata": {
        "id": "haiwHyk01YW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jr6sk80yRe4",
        "outputId": "32662660-60ff-495c-9d71-a34231efe5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMTModel(\n",
              "  (encoder): Encoder(\n",
              "    (dropout_l): Dropout(p=0.15, inplace=False)\n",
              "    (dropout_l2): Dropout(p=0.15, inplace=False)\n",
              "    (embedding): Embedding(3, 300, padding_idx=0)\n",
              "    (LSTM): LSTM(300, 150, num_layers=2, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(50000, 300, padding_idx=0)\n",
              "    (dropout_l1): Dropout(p=0.15, inplace=False)\n",
              "    (LSTM): LSTM(600, 300, num_layers=2, batch_first=True, dropout=0.15)\n",
              "    (dropout_l2): Dropout(p=0.15, inplace=False)\n",
              "    (linear_attn_in): Linear(in_features=300, out_features=300, bias=True)\n",
              "    (linear_attn_out): Linear(in_features=600, out_features=300, bias=True)\n",
              "  )\n",
              "  (linear): Linear(in_features=300, out_features=50000, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from NMT.BCN import BCN\n",
        "classification = BCN(config=params, nmtModel=model, num_labels=2)\n",
        "classification.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHMUn2ZTdmLs",
        "outputId": "b62302a8-22cb-4d7b-d0f5-4ecba5010cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCN(\n",
              "  (encoder): Encoder(\n",
              "    (dropout_l): Dropout(p=0.15, inplace=False)\n",
              "    (dropout_l2): Dropout(p=0.15, inplace=False)\n",
              "    (embedding): Embedding(3, 300, padding_idx=0)\n",
              "    (LSTM): LSTM(300, 150, num_layers=2, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=600, out_features=128, bias=True)\n",
              "  (bilstm_encoder): LSTM(128, 128, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  (bilstm_integrator): LSTM(768, 128, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  (attentive_pooling_proj): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout_pool): Dropout(p=0.15, inplace=False)\n",
              "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxout1): Maxout(\n",
              "    (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (dropout_m1): Dropout(p=0.15, inplace=False)\n",
              "  (maxout2): Maxout(\n",
              "    (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout_m2): Dropout(p=0.15, inplace=False)\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_sentence = torch.randint(0, 2, [sentence_len])\n",
        "rand_classification_l, class_probs = classification(rand_sentence)"
      ],
      "metadata": {
        "id": "4Dqjbr_Sd5_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3j_laS0ZoGf",
        "outputId": "269f5860-9cf1-42b8-da2d-f7e492c28a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4749, 0.5251]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in classification.named_parameters():\n",
        "  print(name, param.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Ltfnb63XK4",
        "outputId": "72bdf773-cc9c-4d45-f151-07372630c5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder.embedding.weight torch.Size([3, 300])\n",
            "encoder.LSTM.weight_ih_l0 torch.Size([600, 300])\n",
            "encoder.LSTM.weight_hh_l0 torch.Size([600, 150])\n",
            "encoder.LSTM.bias_ih_l0 torch.Size([600])\n",
            "encoder.LSTM.bias_hh_l0 torch.Size([600])\n",
            "encoder.LSTM.weight_ih_l0_reverse torch.Size([600, 300])\n",
            "encoder.LSTM.weight_hh_l0_reverse torch.Size([600, 150])\n",
            "encoder.LSTM.bias_ih_l0_reverse torch.Size([600])\n",
            "encoder.LSTM.bias_hh_l0_reverse torch.Size([600])\n",
            "encoder.LSTM.weight_ih_l1 torch.Size([600, 300])\n",
            "encoder.LSTM.weight_hh_l1 torch.Size([600, 150])\n",
            "encoder.LSTM.bias_ih_l1 torch.Size([600])\n",
            "encoder.LSTM.bias_hh_l1 torch.Size([600])\n",
            "encoder.LSTM.weight_ih_l1_reverse torch.Size([600, 300])\n",
            "encoder.LSTM.weight_hh_l1_reverse torch.Size([600, 150])\n",
            "encoder.LSTM.bias_ih_l1_reverse torch.Size([600])\n",
            "encoder.LSTM.bias_hh_l1_reverse torch.Size([600])\n",
            "fc.weight torch.Size([128, 600])\n",
            "fc.bias torch.Size([128])\n",
            "bilstm_encoder.weight_ih_l0 torch.Size([512, 128])\n",
            "bilstm_encoder.weight_hh_l0 torch.Size([512, 128])\n",
            "bilstm_encoder.bias_ih_l0 torch.Size([512])\n",
            "bilstm_encoder.bias_hh_l0 torch.Size([512])\n",
            "bilstm_encoder.weight_ih_l0_reverse torch.Size([512, 128])\n",
            "bilstm_encoder.weight_hh_l0_reverse torch.Size([512, 128])\n",
            "bilstm_encoder.bias_ih_l0_reverse torch.Size([512])\n",
            "bilstm_encoder.bias_hh_l0_reverse torch.Size([512])\n",
            "bilstm_integrator.weight_ih_l0 torch.Size([512, 768])\n",
            "bilstm_integrator.weight_hh_l0 torch.Size([512, 128])\n",
            "bilstm_integrator.bias_ih_l0 torch.Size([512])\n",
            "bilstm_integrator.bias_hh_l0 torch.Size([512])\n",
            "bilstm_integrator.weight_ih_l0_reverse torch.Size([512, 768])\n",
            "bilstm_integrator.weight_hh_l0_reverse torch.Size([512, 128])\n",
            "bilstm_integrator.bias_ih_l0_reverse torch.Size([512])\n",
            "bilstm_integrator.bias_hh_l0_reverse torch.Size([512])\n",
            "attentive_pooling_proj.weight torch.Size([1, 256])\n",
            "attentive_pooling_proj.bias torch.Size([1])\n",
            "bn1.weight torch.Size([1024])\n",
            "bn1.bias torch.Size([1024])\n",
            "maxout1.fc.weight torch.Size([1024, 1024])\n",
            "maxout1.fc.bias torch.Size([1024])\n",
            "maxout2.fc.weight torch.Size([256, 256])\n",
            "maxout2.fc.bias torch.Size([256])\n",
            "bn2.weight torch.Size([256])\n",
            "bn2.bias torch.Size([256])\n",
            "classifier.weight torch.Size([2, 64])\n",
            "classifier.bias torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.rand([batch_size, sentence_len, glove_cove])"
      ],
      "metadata": {
        "id": "hNkJzgXcsjuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_sentence = torch.randint(0, 2, [sentence_len])"
      ],
      "metadata": {
        "id": "DfKKmtFJeYCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del classification\n",
        "classification = BCN2(config=params, nmtModel=model, num_labels=2)\n",
        "classification.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V046dq-PEKfF",
        "outputId": "f4cfb380-dbc2-4b69-8856-26d22b56d8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCN2(\n",
              "  (encoder): Encoder(\n",
              "    (dropout_l): Dropout(p=0.15, inplace=False)\n",
              "    (dropout_l2): Dropout(p=0.15, inplace=False)\n",
              "    (embedding): Embedding(3, 300, padding_idx=0)\n",
              "    (LSTM): LSTM(300, 150, num_layers=2, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=600, out_features=128, bias=True)\n",
              "  (bilstm_encoder): LSTM(128, 128, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  (bilstm_integrator): LSTM(768, 128, batch_first=True, dropout=0.15, bidirectional=True)\n",
              "  (attentive_pooling_proj): Linear(in_features=256, out_features=1, bias=True)\n",
              "  (dropout_pool): Dropout(p=0.15, inplace=False)\n",
              "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxout1): Maxout(\n",
              "    (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (dropout_m1): Dropout(p=0.15, inplace=False)\n",
              "  (maxout2): Maxout(\n",
              "    (fc): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout_m2): Dropout(p=0.15, inplace=False)\n",
              "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_classification_l, class_prob = classification(rand_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI8eSweUeee-",
        "outputId": "2ffba189-0dbb-455b-84e9-1fe1b6e11be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_sentences dim torch.Size([30])\n",
            "input_sentences reshaped torch.Size([1, 30])\n",
            "input type torch.int64\n",
            "padmask type torch.uint8\n",
            "input type torch.int64\n",
            "padmask type torch.uint8\n",
            "input type torch.int64\n",
            "padmask type torch.uint8\n",
            "self_attentive logits dim torch.Size([1, 30])\n",
            "self_attentive logits post sm torch.Size([1, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QKI7okXHjdF",
        "outputId": "13deeab9-3066-4d1b-cf44-746aae81c16d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1356, -0.0605]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsfcwUTAIGvK",
        "outputId": "cb5f123b-a3bc-47f5-fa75-af3e9fcadee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4799, 0.5201]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_classification # with no detach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW7mEdAomfl-",
        "outputId": "f02c6f38-8d5d-4468-c99e-ed8205171a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0892,  0.0429]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}